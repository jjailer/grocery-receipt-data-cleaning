{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70436809-26a0-4bf1-9ebe-e61655145d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Examine Large Baskets\n",
    "# A basket is a tuple (ID, Session, Scan, Date)\n",
    "\n",
    "for df in df_all:\n",
    "    for pid in df.ID.unique():\n",
    "        for session in df.loc[df.ID == pid, 'Session'].unique():\n",
    "            for scan in df.loc[(df.ID == pid) & (df.Session == session), 'Scan'].unique():\n",
    "                for date in df.loc[(df.ID == pid) & (df.Session == session) & (df.Scan == scan), 'Date'].unique():\n",
    "                    if df[(df.ID == pid) & (df.Session == session) & (df.Scan == scan) & (df.Date == date)].shape[0] >= 40:\n",
    "                        print(f'({pid}, {session}, {scan}):', [str(d) for d in df.loc[(df.ID == pid) & (df.Session == session) & (df.Scan == scan), 'Date'].unique()])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155aa48e-f93b-4022-93d2-c97f69461754",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examine Missing Scan / ReceiptNum\n",
    "for df in df_all:\n",
    "    for pid in df.ID.unique():\n",
    "        for session in df.loc[df.ID == pid, 'Session'].unique():\n",
    "            for date in df.loc[(df.ID == pid) & (df.Session == session) & (df.Scan == -1), 'Date'].unique():\n",
    "                print(f'({pid}, {session}, -1):', [str(d) for d in df.loc[(df.ID == pid) & (df.Session == session) & (df.Scan == -1), 'Date'].unique()])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16748a9f-1a03-4583-970a-acc3a25391b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scan / ReceiptNum with multiple dates\n",
    "for df in df_all:\n",
    "    for pid in df.ID.unique():\n",
    "        for session in df.loc[df.ID == pid, 'Session'].unique():\n",
    "            for scan in df.loc[(df.ID == pid) & (df.Session == session), 'Scan'].unique():\n",
    "                if (len(df.loc[(df.ID == pid) & (df.Session == session) & (df.Scan == scan), 'Date'].unique()) > 1) and (scan != -1):\n",
    "                    print(f'({pid}, {session}, {scan}):', [str(d) for d in df.loc[(df.ID == pid) & (df.Session == session) & (df.Scan == scan), 'Date'].unique()])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46fdd0a-d478-49fe-bd44-b04ca951c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: explore evidence of systemic error\n",
    "# Examine large baskets for multiple receipt error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d80899-1437-4ef4-a05c-93fb36c38e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Basket item verification across shared participants\n",
    "\n",
    "## Build multi-index (ID, Basket, ItemNum) \n",
    "for df in df_shared:\n",
    "    # Generate Basket column\n",
    "    df['Basket'] = np.nan    \n",
    "    for pid in df['ID'].unique():\n",
    "        basket_counter = 0\n",
    "        \n",
    "        for session in df.loc[df['ID'] == pid, 'Session'].unique():\n",
    "            \n",
    "            for receipt in df.loc[(df['ID'] == pid) & (df['Session'] == session), 'Receipt'].unique():\n",
    "                basket_counter += 1\n",
    "                df.loc[(df['ID'] == pid) & (df['Session'] == session) & (df['Receipt'] == receipt), 'Basket'] = basket_counter\n",
    "                # TODO interate on unique dates\n",
    "\n",
    "    df['Basket'] = df['Basket'].astype('Int16')\n",
    "\n",
    "    # Generate ItemNum column\n",
    "    df['ItemNum'] = np.nan  \n",
    "    for pid in df['ID'].unique():\n",
    "        \n",
    "        for basket in df.loc[df['ID'] == pid, 'BasketNum'].unique():\n",
    "            df.loc[(df['ID'] == pid) & (df['BasketNum'] == basket), 'ItemNum'] = \\\n",
    "                    range(1, df.loc[(df['ID'] == pid) & (df['BasketNum'] == basket), 'ItemNum'].size + 1)\n",
    "\n",
    "    df['ItemNum'] = df['ItemNum'].astype('Int16')\n",
    "    df.drop(columns = ['Session', 'ReceiptNum'], inplace = True)\n",
    "\n",
    "    # Create multi-index\n",
    "    df.set_index(['ID', 'BasketNum', 'ItemNum'], inplace = True)\n",
    "    df.sort_index(inplace = True)\n",
    "    assert df.index.is_monotonic_increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e393c-417b-437d-ba37-267e445a11a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Statistics on shared multi-indicies\n",
    "assert df_shared[0].index.unique(0).equals(df_shared[1].index.unique(0)) and df_shared[1].index.unique(0).equals(df_shared[2].index.unique(0)) \n",
    "\n",
    "# Symmetric difference of three sets = (A delta B delta C) - (A & B & C)\n",
    "# Use ^ for symmetric difference\n",
    "index_sym_diff = list(set(df_shared[0].loc[shared_ids].index.symmetric_difference(df_shared[1].loc[shared_ids].index).symmetric_difference(df_shared[2].loc[shared_ids].index).tolist()) \\\n",
    "      - set(df_shared[0].loc[shared_ids].index.intersection(df_shared[1].loc[shared_ids].index).intersection(df_shared[2].loc[shared_ids].index).tolist()))\n",
    "index_sym_diff = sorted(sorted(sorted(index_sym_diff, key = lambda i: i[2]), key = lambda i: i[1]), key = lambda i: i[0])\n",
    "print('Symmetric difference of three indices\\n', index_sym_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e9c610-cc05-4864-a4da-abdc3ce63fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check for basket count agreement\n",
    "for pid in df_shared[0].index.unique(0):\n",
    "    print('\\nID:', pid)\n",
    "    for df in df_shared:\n",
    "        print(df.loc[pid].index.unique(0)) # TODO restrict to PID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7329f-dff7-46d8-8fc9-cc29ac5377f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unusable rows\n",
    "essential_drop_count, unknown_drop_count, duplicate_drop_count, total_drop_count = [], [], [], []\n",
    "for df in df_all:\n",
    "    # missing essential values\n",
    "    essential_drop_count.append(df[['ID', 'Session', 'ReceiptNum', 'Item']].isna().sum().sum())\n",
    "    df.dropna(subset = ['ID', 'Session', 'ReceiptNum', 'Item'], inplace = True)\n",
    "    \n",
    "    # unreliable\n",
    "    unknown_drop_count.append(df[df['Unknown'] == 'x'].isna().sum().sum())\n",
    "    df.drop(df[df['Unknown'] == 'x'].index, inplace = True)\n",
    "    \n",
    "    # duplicate receipts\n",
    "    duplicate_drop_count.append(df['Comment'].str.contains(r'duplicate|repeat').sum())\n",
    "    df.drop(df[df['Comment'].str.contains(r'duplicate|repeat')].index, inplace = True)\n",
    "    \n",
    "    assert df[['ID', 'Session', 'ReceiptNum', 'Item']].notna().all(axis = None)\n",
    "    assert df_max['Unknown'].isna().all()\n",
    "    assert not df['Comment'].str.contains(r'duplicate|repeat').any()\n",
    "\n",
    "print('Number of columns dropped due to missing essential columns:', essential_drop_count)\n",
    "print('Number of columns dropped due to item being marked as \"unknown\":', unknown_drop_count)\n",
    "print('Number of duplicate columns dropped:', duplicate_drop_count)\n",
    "\n",
    "total_drop_count = [sum(c) for c in zip(essential_drop_count, unknown_drop_count, duplicate_drop_count)]\n",
    "print('Total number of dropped rows:', total_drop_count)\n",
    "\n",
    "drop_percentage = [round(c[0] / c[1] * 100) for c in zip(total_drop_count, df_sizes)]\n",
    "print('Drop percentage:', drop_percentage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
