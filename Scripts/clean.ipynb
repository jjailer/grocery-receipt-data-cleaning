{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478323c-dd2e-4dde-971d-02ead918817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be84561-d288-47e6-b04d-6950972bb847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../Data/'\n",
    "FILE_NAME = 'Max, Samantha, Maria data.xlsx'\n",
    "\n",
    "xls = pd.ExcelFile(DATA_PATH + FILE_NAME)\n",
    "df_max = pd.read_excel(xls, sheet_name = 'Max', parse_dates = [3])\n",
    "df_mar = pd.read_excel(xls, sheet_name = 'Maria', parse_dates = [3])\n",
    "df_sam = pd.read_excel(xls, sheet_name = 'Samantha', parse_dates = [3])\n",
    "\n",
    "df_all = [df_max, df_mar, df_sam]\n",
    "df_sizes = [df.shape[0] for df in df_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01681203-f577-4055-b2a8-4014338ba893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Standize Number of Columns\n",
    "\n",
    "# Max's data set lacks coupon column\n",
    "df_mar.drop(columns = 'coupon', inplace = True)\n",
    "df_sam.drop(columns = 'Coupon (#)', inplace= True)\n",
    "\n",
    "assert df_max.columns.size == df_mar.columns.size == df_sam.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c363eab-54d4-488f-8ece-d16801dcf21e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Standarize Column Names\n",
    "\n",
    "column_names = ['ID', 'Session', 'Scan', 'Date', 'Item', 'ItemMore', 'Uncertain', 'Unknown', 'Quantity', 'Hit', 'Miss', 'Category', 'Comment']\n",
    "for df in df_all:\n",
    "    df.columns = column_names\n",
    "\n",
    "assert df_max.columns.equals(df_mar.columns) and df_mar.columns.equals(df_sam.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6410e51a-bcd5-4a6d-ba3b-1bd4e80f4526",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fill NaN values\n",
    "\n",
    "for df in df_all:\n",
    "    scan_na_count = df.Scan.isna().sum()\n",
    "    scan_na_percent = round(scan_na_count / df.Scan.shape[0] * 100)\n",
    "    df.loc[:, 'Scan'] = df.Scan.fillna(value = -1)\n",
    "    print(f'Scan {scan_na_percent}% null')\n",
    "    df.loc[:, 'Quantity'] = df.Quantity.fillna(value = 1)\n",
    "    df.loc[:, ['ItemMore', 'Comment']] = df[['ItemMore', 'Comment']].fillna(value = '')\n",
    "    \n",
    "    assert df[['Scan', 'Quantity', 'ItemMore', 'Comment']].notna().all(axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb15e33-e3d9-408f-b1e8-955330a706e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Assign data types \n",
    "\n",
    "# Typos which produced errors during subsequent data type conversion\n",
    "df_sam.loc[df_sam.Scan == datetime.datetime(1900, 1, 1, 0, 0), 'Scan'] = 1\n",
    "df_sam.loc[df_sam.Quantity == '??', 'Quantity'] = 1\n",
    "\n",
    "string_columns = ['Item', 'ItemMore', 'Category', 'Comment']\n",
    "for df in df_all:\n",
    "    df.loc[:, ['ID', 'Session', 'Scan', 'Quantity']] = df[['ID', 'Session', 'Scan', 'Quantity']].astype(int)\n",
    "    df.loc[:, 'Date'] = pd.to_datetime(df.Date, errors = 'coerce')\n",
    "    df.loc[:, 'Date'] = df.loc[:, 'Date'].dt.date\n",
    "    df.loc[:, string_columns] = df[string_columns].astype(str)\n",
    "    \n",
    "    # clean strings\n",
    "    for col in string_columns:\n",
    "        df.loc[:, col] = df[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ee48c-4c7c-4efc-89b0-11162672504b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Validate ID\n",
    "valid_ids = [129, 136, 144, 147, 151, 156, 160, 112, 117, 120,\n",
    "             128, 134, 143, 146, 150, 154, 159, 110, 115, 119,\n",
    "             131, 139, 145, 149, 152, 157, 162, 113, 118, 126,\n",
    "             121, 114, 137, 153, 141, 127, 130, 135, 148, 158]\n",
    "\n",
    "assert all([df.ID.isin(valid_ids).all() for df in df_all])\n",
    "\n",
    "ids_assigned_max = {129, 136, 144, 147, 151, 156, 160, 112, 117, 120} | {121, 114, 137, 153, 141, 127, 130, 135, 148, 158}\n",
    "ids_assigned_mar = {128, 134, 143, 146, 150, 154, 159, 110, 115, 119} | {121, 114, 137, 153, 141, 127, 130, 135, 148, 158}\n",
    "ids_assigned_sam = {131, 139, 145, 149, 152, 157, 162, 113, 118, 126} | {121, 114, 137, 153, 141, 127, 130, 135, 148, 158}\n",
    "\n",
    "ids_max = set(df_max.ID.unique())\n",
    "ids_mar = set(df_mar.ID.unique())\n",
    "ids_sam = set(df_sam.ID.unique())\n",
    "\n",
    "print(\"Missing participant IDs\")\n",
    "print(\"Max:\", ids_assigned_max - ids_max)\n",
    "print(\"Maria:\", ids_assigned_mar - ids_mar)\n",
    "print(\"Samantha:\", ids_assigned_sam - ids_sam)\n",
    "# TODO: Replace with assert empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752d25c-ae3a-464d-a4c4-ca20f8161909",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validate Session \n",
    "valid_sessions = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "assert all([df.Session.isin(valid_sessions).all() for df in df_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6b4fe-45ea-4e5e-88e7-73df360adf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validate ReceiptNum\n",
    "\n",
    "# Typos identified by discontinous scan numbers\n",
    "df_mar.loc[(df_mar.ID == 137) & (df_mar.Scan == 11), 'Scan'] = 1\n",
    "df_mar.loc[(df_mar.ID == 130) & (df_mar.Session == 2) & (df_mar.Date == datetime.date(2020, 8, 3)), 'Scan'] = 1\n",
    "\n",
    "print('Discontinuous receipt numbers')\n",
    "# (136, 1, 3) is empty\n",
    "# (119, 6, 1) is empty\n",
    "# (145, 3, 1&2) DNE\n",
    "for df in df_all:\n",
    "    for pid in df.ID.unique():\n",
    "        for session in df.loc[df.ID == pid, 'Session'].unique():\n",
    "            tmp = list(df.loc[(df.ID == pid) & (df.Session == session), 'Scan'].unique())\n",
    "            if (tmp != list(range(1, len(tmp) + 1))) and (-1 not in tmp):\n",
    "                print(f'({pid}, {session}):', tmp)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de401015-eaf6-40dc-aea0-0dc04302649b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Validate Date\n",
    "\n",
    "# Typos found by examining min and max dates\n",
    "df_mar.loc[df_mar.Date == datetime.date(2002, 9, 10), 'Date'] = datetime.date(2020, 9, 10)\n",
    "df_mar.loc[df_mar.Date == datetime.date(2002, 9, 21), 'Date'] = datetime.date(2020, 9, 21)\n",
    "df_mar.loc[df_mar.Date == datetime.date(2020, 4, 6), 'Date'] = datetime.date(2020, 6, 4)\n",
    "df_mar.loc[df_mar.Date == datetime.date(2020, 1, 7), 'Date'] = datetime.date(2020, 7, 1)\n",
    "\n",
    "for df in df_all:\n",
    "    print(df.Date.dropna().min(), df.Date.dropna().max(), '\\n')\n",
    "    \n",
    "assert [datetime.date(2020, 5, 1) < df.Date.dropna().min() for df in df_all]\n",
    "assert [df.Date.dropna().max() < datetime.date(2020, 12, 31) for df in df_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f578b-7cc9-46f8-b20b-4d39fbd73e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validate Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6bab43-e188-400c-9043-02a007a8fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max.to_csv(DATA_PATH + 'clean_max.csv')\n",
    "df_mar.to_csv(DATA_PATH + 'clean_mar.csv')\n",
    "df_sam.to_csv(DATA_PATH + 'clean_sam.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
