{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9478323c-dd2e-4dde-971d-02ead918817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9be84561-d288-47e6-b04d-6950972bb847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joseph\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:211: UserWarning: Cell D2858 is marked as a date but the serial value 6684137.0 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "data_path = '../Data/'\n",
    "file_name = 'Max, Samantha, Maria data.xlsx'\n",
    "xls = pd.ExcelFile(data_path + file_name)\n",
    "df_max = pd.read_excel(xls, sheet_name = 'Max', parse_dates = [3])\n",
    "df_mar = pd.read_excel(xls, sheet_name = 'Maria', parse_dates = [3])\n",
    "df_sam = pd.read_excel(xls, sheet_name = 'Samantha', parse_dates = [3])\n",
    "\n",
    "df_all = [df_max, df_mar, df_sam]\n",
    "df_sizes = [df.shape[0] for df in df_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01681203-f577-4055-b2a8-4014338ba893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Standize Number of Columns\n",
    "df_mar.drop(columns = 'coupon', inplace = True)\n",
    "df_sam.drop(columns = 'Coupon (#)', inplace= True)\n",
    "# Max data set lacks coupon column\n",
    "\n",
    "assert df_max.columns.size == df_mar.columns.size == df_sam.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c363eab-54d4-488f-8ece-d16801dcf21e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Standarize Column Names\n",
    "column_names = ['ID', 'Session', 'ReceiptNum', 'ReceiptDate', 'Item', 'Item2',\n",
    "                 'Uncertain', 'Unknown', 'Quantity', 'Hit', 'Miss', 'Category', 'Comment']\n",
    "for df in df_all:\n",
    "    df.columns = column_names\n",
    "\n",
    "assert df_max.columns.equals(df_mar.columns) and df_mar.columns.equals(df_sam.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6410e51a-bcd5-4a6d-ba3b-1bd4e80f4526",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fill NaN values\n",
    "for df in df_all:\n",
    "    # when receipt number is null, assume all items came from a single receipt for that session\n",
    "    df.loc[:, ['ReceiptNum', 'Quantity']] = df[['ReceiptNum', 'Quantity']].fillna(value = 1)\n",
    "    df.loc[:, ['Item2', 'Comment']] = df[['Item2', 'Comment']].fillna(value = '')\n",
    "    \n",
    "    assert df[['ReceiptNum', 'Quantity', 'Item2', 'Comment']].notna().all(axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deb15e33-e3d9-408f-b1e8-955330a706e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Assign data types \n",
    "\n",
    "# Typos which produced errors during subsequent data type conversion\n",
    "df_sam.loc[df_sam.ReceiptNum == datetime.datetime(1900, 1, 1, 0, 0), 'ReceiptNum'] = 1\n",
    "df_sam.loc[df_sam['Quantity'] == '??', 'Quantity'] = 1\n",
    "\n",
    "string_columns = ['Item', 'Item2', 'Category', 'Comment']\n",
    "for df in df_all:\n",
    "    df.loc[:, ['ID', 'Session', 'ReceiptNum', 'Quantity']] = df[['ID', 'Session', 'ReceiptNum', 'Quantity']].astype(pd.Int16Dtype())\n",
    "    df.loc[:, 'ReceiptDate'] = pd.to_datetime(df['ReceiptDate'], errors = 'coerce')\n",
    "    df.loc[:, string_columns] = df[string_columns].astype(str)\n",
    "    \n",
    "    # clean strings\n",
    "    for col in string_columns:\n",
    "        df.loc[:, col] = df[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d2ee48c-4c7c-4efc-89b0-11162672504b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 1) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(129, 2) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(129, 3) <IntegerArray>\n",
      "[1, 2, 3, 4]\n",
      "Length: 4, dtype: Int16\n",
      "(129, 4) <IntegerArray>\n",
      "[1, 2]\n",
      "Length: 2, dtype: Int16\n",
      "(129, 5) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(136, 1) <IntegerArray>\n",
      "[1, 2, 4, 5, 6, 7]\n",
      "Length: 6, dtype: Int16\n",
      "(136, 2) <IntegerArray>\n",
      "[1, 2, 3, 4, 5, 6, 7]\n",
      "Length: 7, dtype: Int16\n",
      "(136, 4) <IntegerArray>\n",
      "[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "Length: 8, dtype: Int16\n",
      "(136, 5) <IntegerArray>\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Length: 9, dtype: Int16\n",
      "(121, 1) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(121, 2) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(121, 3) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(121, 4) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(121, 5) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(121, 6) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(114, 1) <IntegerArray>\n",
      "[1, 2, 3]\n",
      "Length: 3, dtype: Int16\n",
      "(114, 2) <IntegerArray>\n",
      "[1, 2]\n",
      "Length: 2, dtype: Int16\n",
      "(114, 3) <IntegerArray>\n",
      "[1, 2]\n",
      "Length: 2, dtype: Int16\n",
      "(114, 4) <IntegerArray>\n",
      "[1, 2]\n",
      "Length: 2, dtype: Int16\n",
      "(114, 5) <IntegerArray>\n",
      "[1, 2]\n",
      "Length: 2, dtype: Int16\n",
      "(114, 6) <IntegerArray>\n",
      "[1, 2, 3]\n",
      "Length: 3, dtype: Int16\n",
      "(137, 1) <IntegerArray>\n",
      "[1, 2]\n",
      "Length: 2, dtype: Int16\n",
      "(137, 2) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(137, 3) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(137, 4) <IntegerArray>\n",
      "[1, 2]\n",
      "Length: 2, dtype: Int16\n",
      "(137, 5) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(137, 6) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(153, 1) <IntegerArray>\n",
      "[1, 2]\n",
      "Length: 2, dtype: Int16\n",
      "(153, 2) <IntegerArray>\n",
      "[1, 2, 3, 4]\n",
      "Length: 4, dtype: Int16\n",
      "(153, 3) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(153, 4) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(153, 5) <IntegerArray>\n",
      "[1, 2]\n",
      "Length: 2, dtype: Int16\n",
      "(141, 1) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(141, 2) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(141, 3) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(141, 4) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(141, 5) <IntegerArray>\n",
      "[1, 2]\n",
      "Length: 2, dtype: Int16\n",
      "(127, 1) <IntegerArray>\n",
      "[1, 2, 3]\n",
      "Length: 3, dtype: Int16\n",
      "(127, 2) <IntegerArray>\n",
      "[1, 2, 3]\n",
      "Length: 3, dtype: Int16\n",
      "(127, 4) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(127, 5) <IntegerArray>\n",
      "[1, 2, 3, 4]\n",
      "Length: 4, dtype: Int16\n",
      "(127, 6) <IntegerArray>\n",
      "[1, 2]\n",
      "Length: 2, dtype: Int16\n",
      "(130, 2) <IntegerArray>\n",
      "[1, 2, 3, 4, 5]\n",
      "Length: 5, dtype: Int16\n",
      "(130, 3) <IntegerArray>\n",
      "[1, 2, 3, 4, 5, 6, 7]\n",
      "Length: 7, dtype: Int16\n",
      "(130, 4) <IntegerArray>\n",
      "[1, 2, 3, 4]\n",
      "Length: 4, dtype: Int16\n",
      "(130, 5) <IntegerArray>\n",
      "[1, 2, 3, 4]\n",
      "Length: 4, dtype: Int16\n",
      "(135, 1) <IntegerArray>\n",
      "[1, 2, 3, 4]\n",
      "Length: 4, dtype: Int16\n",
      "(135, 2) <IntegerArray>\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Length: 9, dtype: Int16\n",
      "(135, 4) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(135, 5) <IntegerArray>\n",
      "[1]\n",
      "Length: 1, dtype: Int16\n",
      "(135, 6) <IntegerArray>\n",
      "[1, 2, 3]\n",
      "Length: 3, dtype: Int16\n",
      "(144, 1) <IntegerArray>\n",
      "[1, 2, 3, 4, 5, 6]\n",
      "Length: 6, dtype: Int16\n"
     ]
    }
   ],
   "source": [
    "### TODO: Validate ID\n",
    "valid_ids = [129, 136, 144, 147, 151, 156, 160, 112, 117, 120,\n",
    "             128, 134, 143, 146, 150, 154, 159, 110, 115, 119,\n",
    "             131, 139, 145, 149, 152, 157, 162, 113, 118, 126,\n",
    "             121, 114, 137, 153, 141, 127, 130, 135, 148, 158]\n",
    "\n",
    "assert all([df['ID'].isin(valid_ids).all() for df in df_all])\n",
    "\n",
    "### Participant Assignment Verification\n",
    "ids_assigned_max = {129, 136, 144, 147, 151, 156, 160, 112, 117, 120, 121, 114, 137, 153, 141, 127, 130, 135, 148, 158}\n",
    "ids_assigned_mar = {128, 134, 143, 146, 150, 154, 159, 110, 115, 119, 121, 114, 137, 153, 141, 127, 130, 135, 148, 158}\n",
    "ids_assigned_sam = {131, 139, 145, 149, 152, 157, 162, 113, 118, 126, 121, 114, 137, 153, 141, 127, 130, 135, 148, 158}\n",
    "\n",
    "print(\"Missing participant IDs\")\n",
    "# All should be empty\n",
    "print(\"Max:\", set(ids_assigned_max.difference(df_max['ID'].unique())))\n",
    "print(\"Maria:\", set(ids_assigned_mar.difference(df_mar['ID'].unique())))\n",
    "print(\"Samantha:\", set(ids_assigned_sam.difference(df_sam['ID'].unique())))\n",
    "\n",
    "# Shared participant verification\n",
    "max_ids = set(df_max.ID.unique())\n",
    "mar_ids = set(df_mar.ID.unique())\n",
    "sam_ids = set(df_sam.ID.unique())\n",
    "\n",
    "# Venn diagram\n",
    "plt.figure(figsize=(11,11))\n",
    "v = venn3([max_ids, mar_ids, sam_ids], ('Max', 'Maria', 'Samantha'))\n",
    "\n",
    "v.get_label_by_id('100').set_text('\\n'.join(str(s) for s in (max_ids - mar_ids - sam_ids)))\n",
    "v.get_label_by_id('110').set_text('\\n'.join(str(s) for s in (max_ids & mar_ids - sam_ids)))\n",
    "v.get_label_by_id('010').set_text('\\n'.join(str(s) for s in (mar_ids - max_ids - sam_ids)))\n",
    "v.get_label_by_id('101').set_text('\\n'.join(str(s) for s in (max_ids - mar_ids & sam_ids)))\n",
    "v.get_label_by_id('111').set_text('\\n'.join(str(s) for s in (max_ids & mar_ids & sam_ids)))\n",
    "v.get_label_by_id('011').set_text('\\n'.join(str(s) for s in (mar_ids & sam_ids - max_ids)))\n",
    "v.get_label_by_id('001').set_text('\\n'.join(str(s) for s in (sam_ids - max_ids - mar_ids)))\n",
    "\n",
    "plt.savefig('../Output/id_verification_venn_diagram.png')\n",
    "\n",
    "# Pair-wise shared participants\n",
    "max_mar_ids = max_ids & mar_ids - sam_ids\n",
    "max_sam_ids = max_ids & sam_ids - mar_ids\n",
    "mar_sam_ids = mar_ids & sam_ids - max_ids\n",
    "shared_ids = max_ids & mar_ids & sam_ids\n",
    "df_shared = []\n",
    "for df in df_all:\n",
    "    df_shared.append(df[df['ID'].isin(shared_ids)].copy())\n",
    "\n",
    "# Shared participants: {121, 114, 137, 153, 141, 127, 130, 135, 148, 158}\n",
    "print('Max-Mar shared IDs: ', max_mar_ids)\n",
    "print('Max-Sam shared IDs: ', max_sam_ids)\n",
    "print('Mar-Sam shared IDs: ', mar_sam_ids)\n",
    "print('Max-Mar-Sam shared IDs: ', shared_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752d25c-ae3a-464d-a4c4-ca20f8161909",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Validate Session \n",
    "valid_sessions = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "assert all([df['Session'].isin(valid_sessions).all() for df in df_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6b4fe-45ea-4e5e-88e7-73df360adf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Validate ReceiptNum\n",
    "\n",
    "#TODO I think these receipt numbers should be contiguous\n",
    "# IntegerArray???\n",
    "for pid in df_max['ID'].unique():\n",
    "    for session in df_max.loc[df_max['ID'] == pid, 'Session'].unique():\n",
    "        print(f'({pid}, {session})', df_max.loc[(df_max['ID'] == pid) & (df_max['Session'] == session), 'ReceiptNum'].unique())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a81eb391-d162-4056-a955-28a93ca26503",
   "metadata": {
    "tags": []
   },
   "source": [
    "TODO\n",
    "consistency in Category column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
