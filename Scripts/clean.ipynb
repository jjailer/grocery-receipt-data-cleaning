{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9478323c-dd2e-4dde-971d-02ead918817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9be84561-d288-47e6-b04d-6950972bb847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joseph\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:211: UserWarning: Cell D2858 is marked as a date but the serial value 6684137.0 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../Data/'\n",
    "FILE_NAME = 'Max, Samantha, Maria data.xlsx'\n",
    "\n",
    "xls = pd.ExcelFile(DATA_PATH + FILE_NAME)\n",
    "df_max = pd.read_excel(xls, sheet_name='Max', parse_dates=[3])\n",
    "df_mar = pd.read_excel(xls, sheet_name='Maria', parse_dates=[3])\n",
    "df_sam = pd.read_excel(xls, sheet_name='Samantha', parse_dates=[3])\n",
    "\n",
    "df_all = [df_max, df_mar, df_sam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01681203-f577-4055-b2a8-4014338ba893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Standize the number of columns\n",
    "\n",
    "# Max's data set lacks coupon column -- drop\n",
    "df_mar.drop(columns='coupon', inplace=True)\n",
    "df_sam.drop(columns='Coupon (#)', inplace=True)\n",
    "\n",
    "assert (df_max.columns.size == df_mar.columns.size == df_sam.columns.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c363eab-54d4-488f-8ece-d16801dcf21e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Standarize the column names\n",
    "\n",
    "# TODO: Receipt vs Scan\n",
    "column_names = ['ID', 'Session', 'Receipt', 'Date', \n",
    "                'Item', 'ItemMore', 'Uncertain', 'Unknown', \n",
    "                'Quantity', 'Hit', 'Miss', 'Category', 'Comment']\n",
    "\n",
    "str_columns = ['Item', 'ItemMore', 'Category', 'Comment']\n",
    "int_columns = ['ID', 'Session', 'Receipt', 'Quantity']\n",
    "\n",
    "for df in df_all:\n",
    "    df.columns = column_names\n",
    "\n",
    "assert (df_max.columns.equals(df_mar.columns) and df_mar.columns.equals(df_sam.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6410e51a-bcd5-4a6d-ba3b-1bd4e80f4526",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fill NaN values\n",
    "\n",
    "for df in df_all:\n",
    "    df.loc[:, 'Receipt'] = df.Receipt.fillna(value=0)\n",
    "    df.loc[:, 'Quantity'] = df.Quantity.fillna(value=1)\n",
    "    df.loc[:, str_columns] = df[str_columns].fillna(value='')\n",
    "    \n",
    "    assert df[[*int_columns, *str_columns]].notna().all(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d19a6c-f44c-41fa-90df-722ea86bc7a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paren = re.compile(r'\\(.+\\)')\n",
    "\n",
    "def reformat_modifier(text):\n",
    "    m = paren.search(text)\n",
    "    if m:\n",
    "        text = ' '.join([m.group(0)[1:-1], text])\n",
    "        text = paren.sub('', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deb15e33-e3d9-408f-b1e8-955330a706e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Assign Data Types \n",
    "\n",
    "# Typos which produced errors during data type conversion\n",
    "typo = datetime.datetime(1900, 1, 1, 0, 0)\n",
    "df_sam.loc[df_sam.Receipt == typo, 'Receipt'] = 1\n",
    "df_sam.loc[df_sam.Quantity == '??', 'Quantity'] = 1\n",
    "\n",
    "for df in df_all:\n",
    "    df.loc[:, int_columns] = df[int_columns].astype('int16')\n",
    "    df.loc[:, str_columns] = df[str_columns].astype(str)\n",
    "    df.loc[:, 'Date'] = pd.to_datetime(df.Date, errors='coerce').dt.date\n",
    "    \n",
    "    # clean strings\n",
    "    for col in str_columns:\n",
    "        df.loc[:, col] = df[col].str.lower()    \n",
    "        df.loc[:, col] = df[col].apply(reformat_modifier)\n",
    "        df.loc[:, col] = df[col].str.replace(r'[/()]', ' ', regex=False)\n",
    "        df.loc[:, col] = df[col].str.replace(r'unknown', '', regex=False)\n",
    "        df.loc[:, col] = df[col].str.replace(r'nan', '', regex=False)\n",
    "        df.loc[:, col] = df[col].str.replace(r'?', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d2ee48c-4c7c-4efc-89b0-11162672504b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Validate ID\n",
    "ids_assigned_all = {121, 114, 137, 153, 141, 127, 130, 135, 148, 158}\n",
    "ids_assigned_max = ids_assigned_all | {129, 136, 144, 147, 151, \n",
    "                                       156, 160, 112, 117, 120}\n",
    "ids_assigned_mar = ids_assigned_all | {128, 134, 143, 146, 150, \n",
    "                                       154, 159, 110, 115, 119}\n",
    "ids_assigned_sam = ids_assigned_all | {131, 139, 145, 149, 152, \n",
    "                                       157, 162, 113, 118, 126}\n",
    "\n",
    "valid_ids = (ids_assigned_max | ids_assigned_mar | ids_assigned_sam)\n",
    "\n",
    "assert all([df.ID.isin(valid_ids).all() for df in df_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2752d25c-ae3a-464d-a4c4-ca20f8161909",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validate Session \n",
    "valid_sessions = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "assert all([df.Session.isin(valid_sessions).all() \n",
    "            for df in df_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29a6b4fe-45ea-4e5e-88e7-73df360adf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discontinuous receipt numbers\n",
      "(136, 1): [1, 2, 4, 5, 6, 7]\n",
      "\n",
      "(119, 6): [2, 3, 4, 5]\n",
      "\n",
      "(145, 3): [3, 4]\n",
      "(153, 6): [2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Validate Receipt\n",
    "\n",
    "# Typos identified by discontinous receipt numbers\n",
    "typo = datetime.date(2020, 8, 3)\n",
    "df_mar.loc[(df_mar.ID == 137) & (df_mar.Receipt == 11), 'Receipt'] = 1\n",
    "df_mar.loc[(df_mar.ID == 130) & (df_mar.Session == 2) & (df_mar.Date == typo), 'Receipt'] = 1\n",
    "\n",
    "print('Discontinuous receipt numbers')\n",
    "# (136, 1, 3) is an empty receipt on box\n",
    "# (119, 6, 1) is an empty receipt on box\n",
    "# (145, 3, 1&2) do not exist\n",
    "# (153, 6, 1) is labled 153-6, receipt 0\n",
    "for df in df_all:\n",
    "    for pid in df.ID.unique():\n",
    "        for session in df.loc[df.ID == pid, 'Session'].unique():\n",
    "            tmp = list(\n",
    "                df.loc[(df.ID == pid) & \n",
    "                       (df.Session == session), 'Receipt'].unique())\n",
    "            if 0 in tmp:\n",
    "                tmp.remove(0)\n",
    "            if tmp != list(range(1, len(tmp) + 1)):\n",
    "                print(f'({pid}, {session}):', tmp)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de401015-eaf6-40dc-aea0-0dc04302649b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-04 2020-10-17 \n",
      "\n",
      "2020-05-06 2020-12-08 \n",
      "\n",
      "2020-06-04 2020-11-08 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Validate Date\n",
    "\n",
    "# Typos found by examining date range\n",
    "df_mar.loc[df_mar.Date == datetime.date(2002, 9, 10), 'Date'] = datetime.date(2020, 9, 10)\n",
    "df_mar.loc[df_mar.Date == datetime.date(2002, 9, 21), 'Date'] = datetime.date(2020, 9, 21)\n",
    "df_mar.loc[df_mar.Date == datetime.date(2020, 4, 6), 'Date'] = datetime.date(2020, 6, 4)\n",
    "df_mar.loc[df_mar.Date == datetime.date(2020, 1, 7), 'Date'] = datetime.date(2020, 7, 1)\n",
    "\n",
    "for df in df_all:\n",
    "    print(df.Date.dropna().min(), df.Date.dropna().max(), '\\n')\n",
    "    \n",
    "assert [datetime.date(2020, 5, 1) < df.Date.dropna().min() for df in df_all]\n",
    "assert [df.Date.dropna().max() < datetime.date(2020, 12, 31) for df in df_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d7f578b-7cc9-46f8-b20b-4d39fbd73e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Validate Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1c28b26-4b24-497d-892f-eaf3d2134fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 duplicate rows dropped, 9%\n",
      "0 duplicate rows dropped, 0%\n",
      "25 duplicate rows dropped, 1%\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate receipts\n",
    "for df in df_all:\n",
    "    duplicate_mask = df.Comment.str.contains(r'duplicate|repeat')\n",
    "    duplicate_drop_count = sum(duplicate_mask)\n",
    "    df = df.drop(df[duplicate_mask].index)\n",
    "    print(f'{duplicate_drop_count} duplicate rows dropped, {duplicate_drop_count / df.shape[0]:.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3547d7b-11f3-475e-bdae-95c87f68598e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Create Baskets\n",
    "for df in df_all:\n",
    "    df['Basket'] = None    \n",
    "    for pid in df.ID.unique():\n",
    "        basket_counter = 0\n",
    "        for session in df.loc[df.ID == pid, 'Session'].unique():    \n",
    "            for receipt in df.loc[(df.ID == pid) & (df.Session == session), 'Receipt'].unique():\n",
    "                for date in df.loc[(df.ID == pid) & (df.Session == session) & (df.Receipt == receipt), 'Date'].unique():\n",
    "                    basket_counter += 1\n",
    "                    df.loc[(df.ID == pid) & (df.Session == session) & (df.Receipt == receipt) & \n",
    "                           (df.Date == date), 'Basket'] = basket_counter\n",
    "                    \n",
    "                df.loc[(df.ID == pid) & (df.Session == session) & (df.Receipt == receipt) & \n",
    "                       df.Date.isna(), 'Basket'] = basket_counter + 1\n",
    "                \n",
    "    df['Basket'] = df['Basket'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa6bab43-e188-400c-9043-02a007a8fd2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_max.to_csv(DATA_PATH + 'clean_max.csv')\n",
    "df_mar.to_csv(DATA_PATH + 'clean_mar.csv')\n",
    "df_sam.to_csv(DATA_PATH + 'clean_sam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64967b-f6f9-4c80-808e-c5b508689b81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
