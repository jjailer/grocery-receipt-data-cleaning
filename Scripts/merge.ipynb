{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c248283-b7b1-480a-b641-406ccc6fc1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import gensim.downloader as api\n",
    "word_vectors = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15c97439-9dba-4cda-9f8e-1058149788ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../Data/'\n",
    "FILES = ['clean_max.csv', 'clean_mar.csv', 'clean_sam.csv']\n",
    "#COLS = [0, 1, 14, 5]  # Index, ID, Basket, Item\n",
    "COLS = [0, 1, 2, 5]  # Index, ID, Session, Item\n",
    "DTYPES = {'ID': 'uint8', 'Session': 'uint8', 'Item': str}\n",
    "\n",
    "dfs = [pd.read_csv(DATA_PATH + file, index_col=0, usecols=COLS, dtype=DTYPES) for file in FILES]\n",
    "\n",
    "ids_shared = set.intersection(*[set(df.ID.unique()) for df in dfs])\n",
    "dfs = [df[df.ID.isin(ids_shared)].fillna('').reset_index(drop=True) for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2de8e81-434a-4a83-a332-2dfb406e0d81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def equalize_length(df1, df2):\n",
    "    df1_length, df2_length = len(df1), len(df2)\n",
    "    \n",
    "    if df1_length > df2_length:    \n",
    "        df2 = df2.reindex(list(range(df1_length)))\n",
    "        df2 = df2.fillna('')\n",
    "    elif df2_length > df1_length:\n",
    "        df1 = df1.reindex(list(range(df2_length)))\n",
    "        df1 = df1.fillna('')\n",
    "\n",
    "    assert len(df1) == len(df2)\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096f5e2a-2e18-4cae-a7c4-cc9046f70180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: unpack big functions in order to reduce permutations\n",
    "def compare(df_row):\n",
    "    result = []\n",
    "    df_split = df_row.str.split()\n",
    "  \n",
    "    # return shared words\n",
    "    shared_words = set.intersection(*map(set, df_split))\n",
    "    unshared_words = set.symmetric_difference(*map(set, df_split))\n",
    "    if shared_words:\n",
    "        result.extend(shared_words)\n",
    "        # if both phrases are exhausted return\n",
    "        if not unshared_words:\n",
    "            df_row['WordVec'] = ' '.join(result)\n",
    "            df_row['Distance'] = 0\n",
    "            return df_row\n",
    "    \n",
    "    # discard words outside vocabulary\n",
    "    df_in_voc = [[word for word in phrase if word in word_vectors.vocab] for phrase in df_split]\n",
    "    if not any(df_in_voc):\n",
    "        df_row['WordVec'] = ' '.join([*df_row])\n",
    "        df_row['Distance'] = 999  # large number smaller than inf\n",
    "        return df_row\n",
    "    \n",
    "    # use word vectors to average remaining words\n",
    "    #words = [word for text in df_in_voc for word in text]\n",
    "    most_similar_key, _ = word_vectors.most_similar(positive=[*df_in_voc[0], *df_in_voc[1]])[0]  # take top result\n",
    "    result.append(most_similar_key)\n",
    "    df_row['WordVec'] = ' '.join(result)\n",
    "    df_row['Distance'] = word_vectors.wmdistance(df_split[0], df_split[1])\n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5afc7ef5-8f1f-4575-b640-28e255d6ebd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: unpack big functions in order to reduce permutations\n",
    "def align(df1, df2):\n",
    "    df1, df2 = equalize_length(df1, df2)\n",
    "    \n",
    "    # remove identical matches\n",
    "    result_pairs = []\n",
    "    df1_dropped, df2_dropped = df1.index, df2.index\n",
    "    for df1_idx, df1_word in df1.iteritems():\n",
    "        matches = df2[df2_dropped].str.fullmatch(df1_word)\n",
    "        if any(matches):\n",
    "            match_index = matches.idxmax() # return index of first match\n",
    "            result_pairs.append((df1_idx, match_index))\n",
    "            df1_dropped = df1_dropped.drop(df1_idx)\n",
    "            df2_dropped = df2_dropped.drop(match_index)\n",
    "    \n",
    "    # remove substring matches\n",
    "    df1_split = df1[df1_dropped].str.split()\n",
    "    for df1_idx, df1_words in df1_split.iteritems():\n",
    "        for word in df1_words:\n",
    "            matches = df2[df2_dropped].str.contains(word, regex=False)\n",
    "            if any(matches):\n",
    "                match_index = matches.idxmax() # return index of first match\n",
    "                result_pairs.append((df1_idx, match_index))\n",
    "                df1_dropped = df1_dropped.drop(df1_idx)\n",
    "                df2_dropped = df2_dropped.drop(match_index)\n",
    "                break\n",
    "    \n",
    "    # remove substring matches in the other direction\n",
    "    df2_split = df2[df2_dropped].str.split()\n",
    "    for df2_idx, df2_words in df2_split.iteritems():\n",
    "        for word in df2_words:\n",
    "            matches = df1[df1_dropped].str.contains(word, regex=False)\n",
    "            if any(matches):\n",
    "                match_index = matches.idxmax() # return index of first match\n",
    "                result_pairs.append((match_index, df2_idx))\n",
    "                df1_dropped = df1_dropped.drop(match_index)\n",
    "                df2_dropped = df2_dropped.drop(df2_idx)\n",
    "                break\n",
    "    \n",
    "    # remove additional unmatched empty items\n",
    "    df2_dropped = df2_dropped.drop(df2[df2_dropped][df2[df2_dropped] == ''].index)\n",
    "    #df2_dropped = df2_dropped.drop(df2[df2_dropped].isna().index)\n",
    "    #print(df2[df2_dropped][df2[df2_dropped] == ''].index)\n",
    "    \n",
    "\n",
    "    print(len(df2_dropped), end=' ')\n",
    "    return\n",
    "    # all permutations of remaining indices\n",
    "    perms = list(itertools.permutations(df2_dropped))\n",
    "    print(len(perms), end=' ')\n",
    "    \n",
    "    # TODO: this might be needed\n",
    "    # df1['WordVec'], df2['WordVec'] = None, None\n",
    "    # df1['Distance'], df2['Distance'] = 99, 99\n",
    "    # generate word vectors and similarity\n",
    "    if len(perms) > 1:\n",
    "        total_distance = []\n",
    "        df1_reindexed = df1[df1_dropped].reset_index(drop=True)\n",
    "        for p in tqdm(perms, desc=\"Permutations\", leave=False):\n",
    "            p = pd.Index(p)\n",
    "            total_distance.append(\n",
    "                sum(pd.concat(\n",
    "                    [df1_reindexed, df2[p].reset_index(drop=True)], axis=1).apply(compare, axis=1).Distance))        \n",
    "        # find max permutation\n",
    "        result_index = pd.Index(perms[total_distance.index(min(total_distance))])\n",
    "    else:\n",
    "        result_index = pd.Index(perms[0])\n",
    "    \n",
    "    # return concatendated dataframe with word vectors\n",
    "    top_index_left, top_index_right = map(pd.Index, zip(*result_pairs))\n",
    "    bot_index_left, bot_index_right = df1_dropped, result_index\n",
    "\n",
    "    df_combined = pd.concat([pd.concat([df1[top_index_left].reset_index(drop=True), \n",
    "                                        df2[top_index_right].reset_index(drop=True)], axis=1, ignore_index=True), \n",
    "                             pd.concat([df1[bot_index_left].reset_index(drop=True), \n",
    "                                        df2[bot_index_right].reset_index(drop=True)], axis=1, ignore_index=True)], \n",
    "                            ignore_index=True)\n",
    "    \n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09ad211e-7c7c-4df5-822f-3ffaf71a488c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c5ebe474774c25aaaef92a466432ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IDs:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID=130: 0 4 4 3 3 0 \n",
      "PID=153: 4 9 0 3 5 0 \n",
      "PID=135: 10 11 0 2 11 7 \n",
      "PID=137: 7 1 6 2 6 2 \n",
      "PID=141: 10 3 3 3 19 0 \n",
      "PID=114: 1 1 1 1 1 2 \n",
      "PID=121: 9 3 4 3 9 4 \n",
      "PID=127: 3 8 0 5 9 3 \n"
     ]
    }
   ],
   "source": [
    "### Test hand alignment against algorithm\n",
    "# probably depricated as baskets no longer exist\n",
    "def align_by_algo():\n",
    "    #12 total baskets\n",
    "    df_final = pd.DataFrame()\n",
    "    for basket in tqdm(range(1,2), desc=\"Basket\"):\n",
    "        align(dfs[0].loc[(dfs[0].ID == 137) & (dfs[0].Basket == basket), 'Item'].reset_index(drop=True),\n",
    "              dfs[2].loc[(dfs[2].ID == 137) & (dfs[2].Basket == basket), 'Item'].reset_index(drop=True))\n",
    "        #df_final = pd.concat([df_final, \n",
    "        #                      align(dfs[0].loc[(dfs[0].ID == 137) & (dfs[0].Basket == basket), 'Item'].reset_index(drop=True),\n",
    "        #                            dfs[2].loc[(dfs[2].ID == 137) & (dfs[2].Basket == basket), 'Item'].reset_index(drop=True))], ignore_index=True)\n",
    "    #display(df_final.apply(compare, axis=1))\n",
    "\n",
    "#align_by_algo()\n",
    "    \n",
    "def align_count_free_rows():\n",
    "    for pid in tqdm(ids_shared, desc=\"IDs\"):\n",
    "        print(f'PID={pid}:', end=' ')\n",
    "        for session in range(1, 7):\n",
    "            align(dfs[1].loc[(dfs[1].ID == pid) & (dfs[1].Session == session), 'Item'].reset_index(drop=True),\n",
    "                  dfs[0].loc[(dfs[0].ID == pid) & (dfs[0].Session == session), 'Item'].reset_index(drop=True))\n",
    "        print()\n",
    "        \n",
    "#align_count_free_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b871ae-8279-4eea-b535-7463f1c3902e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Align Data Sets by hand\n",
    "def align_by_hand():\n",
    "    # ID 137 and 114 have low variation\n",
    "    df3 = dfs[2].loc[dfs[2].ID == 137, 'Item'].copy().reset_index(drop=True)\n",
    "\n",
    "    # align by inspecting for proof of concept\n",
    "    df3_aligned = df3.drop([102]).reset_index(drop=True)\n",
    "    \n",
    "    df_hand_aligned = pd.concat([dfs[0].loc[dfs[0].ID == 137, 'Item'].reset_index(drop=True), df3_aligned], axis=1)\n",
    "    df_hand_aligned = df_hand_aligned.apply(compare, axis=1)\n",
    "    display(df_hand_aligned)\n",
    "    \n",
    "#align_by_hand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a430200-92af-44f5-8d9d-74aa069db0fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hair product</td>\n",
       "      <td>shampoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>romaine lettuce</td>\n",
       "      <td>romaine hearts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red grapes</td>\n",
       "      <td>red grapes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white grapes</td>\n",
       "      <td>grapes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gouda cheese</td>\n",
       "      <td>gouda cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>manchego cheese</td>\n",
       "      <td>manchego cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gouda with bacon cheese</td>\n",
       "      <td>blackberries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>orange juice</td>\n",
       "      <td>tomato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>santa fe salad</td>\n",
       "      <td>eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blackberries</td>\n",
       "      <td>noodles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>grape tomatoes</td>\n",
       "      <td>ceasar croutons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>eggs</td>\n",
       "      <td>wheat tortilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>monterey jack cheese</td>\n",
       "      <td>pizza crust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>havarti cheese</td>\n",
       "      <td>bacon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>egg noodles</td>\n",
       "      <td>havarti cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>croutons</td>\n",
       "      <td>green and red lettuce salad mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pizza crust</td>\n",
       "      <td>chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tortillas</td>\n",
       "      <td>orange juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pecan pralines</td>\n",
       "      <td>pecan pralines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cheerios cereal</td>\n",
       "      <td>cereal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tomato juice</td>\n",
       "      <td>tomato juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>crackers</td>\n",
       "      <td>wheat think crackers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>fruit bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>peanut butter</td>\n",
       "      <td>peanut butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>peach preserves</td>\n",
       "      <td>jam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>curry sauce</td>\n",
       "      <td>tartar sauce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cherry preserves</td>\n",
       "      <td>jalfrezi sauce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tartar sauce</td>\n",
       "      <td>bbq wavy chips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>barbecue chips</td>\n",
       "      <td>jalapeno wavy chips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>jalapeno chips</td>\n",
       "      <td>shampoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>white grapes</td>\n",
       "      <td>romaine hearts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>gouda cheese</td>\n",
       "      <td>red grapes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>manchego cheese</td>\n",
       "      <td>grapes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>gouda with bacon cheese</td>\n",
       "      <td>gouda cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>orange juice</td>\n",
       "      <td>manchego cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>santa fe salad</td>\n",
       "      <td>blackberries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>blackberries</td>\n",
       "      <td>tomato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>grape tomatoes</td>\n",
       "      <td>eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>eggs</td>\n",
       "      <td>noodles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>monterey jack cheese</td>\n",
       "      <td>ceasar croutons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>havarti cheese</td>\n",
       "      <td>wheat tortilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>egg noodles</td>\n",
       "      <td>pizza crust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>croutons</td>\n",
       "      <td>bacon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>pizza crust</td>\n",
       "      <td>havarti cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tortillas</td>\n",
       "      <td>green and red lettuce salad mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>breast chicken</td>\n",
       "      <td>chicken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0                                1\n",
       "0              hair product                          shampoo\n",
       "1           romaine lettuce                   romaine hearts\n",
       "2                red grapes                       red grapes\n",
       "3              white grapes                           grapes\n",
       "4              gouda cheese                     gouda cheese\n",
       "5           manchego cheese                  manchego cheese\n",
       "6   gouda with bacon cheese                     blackberries\n",
       "7              orange juice                           tomato\n",
       "8            santa fe salad                             eggs\n",
       "9              blackberries                          noodles\n",
       "10           grape tomatoes                  ceasar croutons\n",
       "11                     eggs                   wheat tortilla\n",
       "12     monterey jack cheese                      pizza crust\n",
       "13           havarti cheese                            bacon\n",
       "14              egg noodles                   havarti cheese\n",
       "15                 croutons  green and red lettuce salad mix\n",
       "16              pizza crust                          chicken\n",
       "17                tortillas                     orange juice\n",
       "18           pecan pralines                   pecan pralines\n",
       "19          cheerios cereal                           cereal\n",
       "20             tomato juice                     tomato juice\n",
       "21                 crackers             wheat think crackers\n",
       "22                pineapple                        fruit bar\n",
       "23            peanut butter                    peanut butter\n",
       "24          peach preserves                              jam\n",
       "25              curry sauce                     tartar sauce\n",
       "26         cherry preserves                   jalfrezi sauce\n",
       "27             tartar sauce                   bbq wavy chips\n",
       "28           barbecue chips              jalapeno wavy chips\n",
       "29           jalapeno chips                          shampoo\n",
       "30             white grapes                   romaine hearts\n",
       "31             gouda cheese                       red grapes\n",
       "32          manchego cheese                           grapes\n",
       "33  gouda with bacon cheese                     gouda cheese\n",
       "34             orange juice                  manchego cheese\n",
       "35           santa fe salad                     blackberries\n",
       "36             blackberries                           tomato\n",
       "37           grape tomatoes                             eggs\n",
       "38                     eggs                          noodles\n",
       "39     monterey jack cheese                  ceasar croutons\n",
       "40           havarti cheese                   wheat tortilla\n",
       "41              egg noodles                      pizza crust\n",
       "42                 croutons                            bacon\n",
       "43              pizza crust                   havarti cheese\n",
       "44                tortillas  green and red lettuce salad mix\n",
       "45           breast chicken                          chicken"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Collect basket outliers for inspection\n",
    "# 0-1 MANY and 1-2 MANY\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "display(pd.concat([dfs[0].loc[(dfs[0].ID == 135) & (dfs[0].Session == 6), 'Item'].reset_index(drop=True),\n",
    "                   dfs[1].loc[(dfs[1].ID == 135) & (dfs[1].Session == 6), 'Item'].reset_index(drop=True)],\n",
    "                      axis=1, ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dca8f286-00d5-4c0f-a4e7-67855ea9b6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70241946\n",
      "('plastic', 0.8458467721939087)\n",
      "4.836613549687386\n"
     ]
    }
   ],
   "source": [
    "item1 = 'cleaning spray'.split()\n",
    "item2 = 'glass wipes'.split()\n",
    "print(word_vectors.n_similarity(item1, item2))\n",
    "print(word_vectors.most_similar(positive=[*item1, *item2])[0])\n",
    "print(word_vectors.wmdistance(item1, item2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6691bc15-f876-43fd-9a97-e74ace5b7c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
