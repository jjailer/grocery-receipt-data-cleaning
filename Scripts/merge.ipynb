{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c248283-b7b1-480a-b641-406ccc6fc1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "import gensim.downloader as api\n",
    "word_vectors = api.load(\"glove-wiki-gigaword-200\")\n",
    "\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15c97439-9dba-4cda-9f8e-1058149788ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../Data/'\n",
    "df_max = pd.read_csv(DATA_PATH + 'clean_max.csv', index_col=0, parse_dates=[3])\n",
    "df_mar = pd.read_csv(DATA_PATH + 'clean_mar.csv', index_col=0, parse_dates=[3])\n",
    "df_sam = pd.read_csv(DATA_PATH + 'clean_sam.csv', index_col=0, parse_dates=[3])\n",
    "\n",
    "df_all = [df_max, df_mar, df_sam]\n",
    "df_sizes = [df.shape[0] for df in df_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082ba0bf-e068-4d9d-8ea5-8e7d68459145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Assign Data Types \n",
    "int_columns = ['ID', 'Session', 'Receipt', 'Quantity']\n",
    "string_columns = ['Item', 'ItemMore', 'Category', 'Comment']\n",
    "for df in df_all:\n",
    "    df.loc[:, int_columns] = df[int_columns].astype(int)\n",
    "    df.loc[:, string_columns] = df[string_columns].astype(str)\n",
    "    df.loc[:, 'Date'] = pd.to_datetime(df.Date, errors='coerce').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e644dc-0e3d-4a70-92eb-c134df71bff6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Shared Participants\n",
    "ids_shared = set(df_max.ID.unique()) & set(df_mar.ID.unique()) & set(df_sam.ID.unique())\n",
    "\n",
    "df_shared = []\n",
    "for df in df_all:\n",
    "    df_shared.append(df[df.ID.isin(ids_shared)].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02315028-b56f-4337-8cff-92b837d40d39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Compare\n",
    "def compare(df):\n",
    "    result = []\n",
    "    item1_split = df['Item1'].split()\n",
    "    item2_split = df['Item3'].split()    \n",
    "    \n",
    "    # shared words\n",
    "    item12_intersection = [word for word in item1_split if word in item2_split]\n",
    "    if item12_intersection:\n",
    "        for word in item12_intersection:\n",
    "            result.append(word)\n",
    "        item1_split = [word for word in item1_split if word not in item12_intersection]\n",
    "        item2_split = [word for word in item2_split if word not in item12_intersection]\n",
    "    \n",
    "    # discard word outside vocabulary\n",
    "    item1 = [word for word in item1_split if word in word_vectors.vocab]\n",
    "    item2 = [word for word in item2_split if word in word_vectors.vocab]\n",
    "    \n",
    "    # if either item is exhausted return\n",
    "    if not item1 or not item2:\n",
    "        return ' '.join(result)\n",
    "    \n",
    "    # use word vectors to average remaining words\n",
    "    wv_result = word_vectors.most_similar(positive=[*item1, *item2])\n",
    "    most_similar_key, _ = wv_result[0]  # look at the first match\n",
    "    result.append(most_similar_key)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b09db3-3f58-4a57-99e6-ba9531dd9095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Pre-process\n",
    "df_hand_aligned['Item1'] = df_hand_aligned['Item1'].str.replace(r'[()?]', '', regex=True)\n",
    "df_hand_aligned['Item1'] = df_hand_aligned['Item1'].str.replace(r'/', ' ', regex=False)\n",
    "df_hand_aligned['Item1'] = df_hand_aligned['Item1'].str.replace(r'unknown', '', regex=False)\n",
    "df_hand_aligned['Item1'] = df_hand_aligned['Item1'].str.replace('nan', '', regex=False)\n",
    "\n",
    "df_hand_aligned['Item3'] = df_hand_aligned['Item3'].str.replace(r'[()?]', '', regex=True)\n",
    "df_hand_aligned['Item3'] = df_hand_aligned['Item3'].str.replace(r'/', ' ', regex=False)\n",
    "df_hand_aligned['Item3'] = df_hand_aligned['Item3'].str.replace(r'unknown', '', regex=False)\n",
    "df_hand_aligned['Item3'] = df_hand_aligned['Item3'].str.replace('nan', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b871ae-8279-4eea-b535-7463f1c3902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Align Data Sets by hand\n",
    "# ID 137 and 114 have low variation\n",
    "df1 = df_shared[0].loc[df_shared[0].ID == 137, ['Item']].copy().reset_index(drop=True)\n",
    "df2 = df_shared[1].loc[df_shared[1].ID == 137, ['Item']].copy().reset_index(drop=True)\n",
    "df3 = df_shared[2].loc[df_shared[2].ID == 137, ['Item']].copy().reset_index(drop=True)\n",
    "\n",
    "# align by inspecting for proof of concept\n",
    "df3 = df3.drop([102]).reset_index(drop=True)\n",
    "df_hand_aligned = pd.concat([df1, df3], axis=1)\n",
    "df_hand_aligned.columns = ['Item1', 'Item3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78a428-9d8e-40ba-930b-ba3a22edaa21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_hand_aligned['WordVec'] = df_hand_aligned.apply(compare, axis=1)\n",
    "df_hand_aligned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
